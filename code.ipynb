{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import nltk.corpus\n",
    "import json\n",
    "import math \n",
    "from nltk import tokenize\n",
    "from nltk.text import TextCollection\n",
    "from nltk.corpus import stopwords \n",
    "import re\n",
    "punctuation=re.compile(r'[-``.?!,:;()|0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Questions=[]\n",
    "with open('Questions.txt',encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        Questions.append(line.rstrip('\\n')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter paragraph :\twhere is London?\n"
     ]
    }
   ],
   "source": [
    "para=input('Enter paragraph :\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = tokenize.sent_tokenize(para.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Questions1 = []  # this will tokenize question and assign term frequecy\n",
    "for index, sentence in enumerate(Questions):\n",
    "    tokenizedWords = sentence.split(' ')\n",
    "    Questions1.append([(word) for word in tokenizedWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictOfWords = [] #this will tokenize pragraph and assign term frequency\n",
    "for index, sentence in enumerate(sents):\n",
    "    tokenizedWords = sentence.split(' ')\n",
    "    dictOfWords.append([(word) for word in tokenizedWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second: remove duplicates from question tokens\n",
    "termFrequencyq = []\n",
    "for i in range(0, len(Questions)):\n",
    "    listOfNoDuplicates = []\n",
    "    for wordFreq in Questions1[i]:\n",
    "        if wordFreq not in listOfNoDuplicates:\n",
    "            listOfNoDuplicates.append(wordFreq)\n",
    "    termFrequencyq.append(listOfNoDuplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second: remove duplicates from paragraph tokens\n",
    "termFrequency =[]\n",
    "for i in range(0, len(sents)):\n",
    "    listOfNoDuplicates = []\n",
    "    for wordFreq in dictOfWords[i]:\n",
    "        if wordFreq not in listOfNoDuplicates:\n",
    "            listOfNoDuplicates.append(wordFreq)\n",
    "    termFrequency.append(listOfNoDuplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_punctuation1=[] # it will remove punctuation from paragraph\n",
    "for i in range(0,len(termFrequency)):\n",
    "    sentence = termFrequency[i]\n",
    "    punctuation1=[]\n",
    "    for words in termFrequency[i]:\n",
    "        word=punctuation.sub(\"\",words)\n",
    "        if len(word)>0:\n",
    "            punctuation1.append((word))\n",
    "    post_punctuation1.append(punctuation1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_punctuation1q=[] # it will remove punctuation from questions\n",
    "for i in range(0,len(termFrequencyq)):\n",
    "    sentence = termFrequencyq[i]\n",
    "    punctuation1q=[]\n",
    "    for words in termFrequencyq[i]:\n",
    "        word=punctuation.sub(\"\",words)\n",
    "        if len(word)>0:\n",
    "            punctuation1q.append(word)\n",
    "    post_punctuation1q.append(punctuation1q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords from questions\n",
    "stop_wordsq = set(stopwords.words('english')) \n",
    "filtered_sentence1q=[] # it will remove stop words\n",
    "for i in range(0,len(post_punctuation1q)):\n",
    "    filtered_sentq=[]\n",
    "    for words in post_punctuation1q[i]:\n",
    "        if words not in stop_wordsq: \n",
    "            filtered_sentq.append(words)        \n",
    "    filtered_sentence1q.append(filtered_sentq) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it will remove stop words from paragraph\n",
    "stop_words = set(stopwords.words('english')) \n",
    "filtered_sentence1=[]\n",
    "for i in range(0,len(post_punctuation1)):\n",
    "    filtered_sent=[]\n",
    "    for words in post_punctuation1[i]:\n",
    "        if words not in stop_words: \n",
    "            filtered_sent.append(words)        \n",
    "    filtered_sentence1.append(filtered_sent) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_sim(str1, str2): \n",
    "    strn=[]\n",
    "    for word in str2:\n",
    "        if word not in strn:\n",
    "            strn.append(word)\n",
    "    for word in str1:\n",
    "        if word not in strn:\n",
    "            strn.append(word)\n",
    "        \n",
    "    strn1=[]\n",
    "    strn2=[]\n",
    "    strnn=0\n",
    "    for i in range(0,len(strn)):\n",
    "        if strn[i] in str1:\n",
    "            strn1.append(math.sqrt(((1)/len(strn))))\n",
    "        else:\n",
    "            strn1.append(0)\n",
    "        if strn[i] in str2:\n",
    "            strn2.append(math.sqrt(((1)/len(strn))))\n",
    "        else:\n",
    "            strn2.append(0)\n",
    "    for i in range(0,len(strn)):        \n",
    "        strnn+=(strn1[i]*strn2[i])\n",
    "\n",
    "    return float(strnn)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1=[]\n",
    "for i in range(0,len(filtered_sentence1)):\n",
    "    for j in range(0,len(filtered_sentence1q)):\n",
    "        if(get_cosine_sim(filtered_sentence1[i],filtered_sentence1q[j])> 0.0 ):\n",
    "            new1.append((Questions[j],get_cosine_sim(filtered_sentence1[i],filtered_sentence1q[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim1=[]\n",
    "sim=[]\n",
    "for i in range(0,len(new1)):\n",
    "    sim1.append(new1[i][1])\n",
    "sim=sorted(sim1,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "finallist=[]\n",
    "for a in range(0,len(new1)):\n",
    "    for b in range(0,len(new1)):\n",
    "        if(sim[a]==new1[b][1]):\n",
    "            finallist.append(new1[b][0])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "finallist1=[]\n",
    "for word in finallist:\n",
    "    if word not in finallist1:\n",
    "        finallist1.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Number for questions :10\n"
     ]
    }
   ],
   "source": [
    "n=int(input(\"Enter Number for questions :\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what died in london? \n",
      "\n",
      "who did beyonce partner with in london? \n",
      "\n",
      "what steet did chopin stay on in london? \n",
      "\n",
      "what company provided chopin with a piano while in london? \n",
      "\n",
      "was watt a fellow of the royal society of edinburgh and the royal society of london? \n",
      "\n",
      "what songs did kanye dedicate to his late mother as his performance at the o2 in london? \n",
      "\n",
      "in addition to hearing him play, what else did people seek from chopin in london? \n",
      "\n",
      "along with minneapolis, london and birmingham, what city contains a notable population of somalis? \n",
      "\n",
      "what word was used by london officials to describe chinese security guards for their treatment of protesters? \n",
      "\n",
      "after the telegraph was extended to the coast of the black sea, how long did it take news of the war to reach london? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(finallist1)):\n",
    "    print(finallist1[i],'\\n')\n",
    "    if i==n-1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
